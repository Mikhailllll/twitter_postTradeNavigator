"""–ü—Ä–∞–≤–∏–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Ç–≤–∏—Ç–æ–≤."""

from __future__ import annotations

import re
import textwrap
from collections.abc import Iterable

MAX_TWEET_LENGTH = 280
BINANCE_LINKS_BLOCK = (
    "–ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏ Binance:\n"
    "‚Ä¢ –ë–∏—Ä–∂–∞: https://www.binance.com\n"
    "‚Ä¢ –ü–æ–¥–¥–µ—Ä–∂–∫–∞: https://www.binance.com/support\n"
    "‚Ä¢ –ê–∫–∞–¥–µ–º–∏—è: https://academy.binance.com"
)

EMOJI_KEYWORDS = {
    "–ª–∏—Å—Ç–∏–Ω–≥": "üÜï",
    "listing": "üÜï",
    "launchpool": "üöÄ",
    "maintenance": "üõ†Ô∏è",
    "upgrade": "üîß",
    "update": "üîÑ",
    "airdrop": "üéÅ",
    "bonus": "üí∞",
    "binance": "üü°",
}

CYRILLIC_PATTERN = re.compile("[–ê-–Ø–∞-—è–Å—ë]")
HASHTAG_WORD_PATTERN = re.compile(r"[A-Za-z0-9]{3,}")


def contains_cyrillic(text: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤."""

    return bool(CYRILLIC_PATTERN.search(text))


def insert_emojis(text: str) -> str:
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —ç–º–æ–¥–∑–∏ –≤ –Ω–∞—á–∞–ª–æ —Ç–µ–∫—Å—Ç–∞."""

    lowered = text.lower()
    emojis: list[str] = []
    for keyword, emoji in EMOJI_KEYWORDS.items():
        if keyword in lowered:
            emojis.append(emoji)
    if not emojis:
        emojis.append("üì¢")
    emojis_str = " ".join(dict.fromkeys(emojis))
    return f"{emojis_str} {text}".strip()


def generate_hashtags(text: str, *, limit: int = 2) -> list[str]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–æ –¥–≤—É—Ö —Ö—ç—à—Ç–µ–≥–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞."""

    candidates = []
    for match in HASHTAG_WORD_PATTERN.finditer(text):
        word = match.group(0)
        if word.isdigit():
            continue
        candidates.append(word.lower())
    unique: list[str] = []
    for candidate in candidates:
        if candidate not in unique:
            unique.append(candidate)
    hashtags = [
        candidate.replace("/", "").replace("-", "") for candidate in unique[:limit]
    ]
    return [f"#{tag}" for tag in hashtags]


def build_thread(*, message_id: int, text: str, hashtags: Iterable[str]) -> list[str]:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç —Ç–≤–∏—Ç-–Ω–∏—Ç–∫—É —Å —Å—Å—ã–ª–∫–æ–π –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª –∏ –±–ª–æ–∫–æ–º —Å—Å—ã–ª–æ–∫ Binance."""

    base_text = insert_emojis(text)
    source_link = f"–ò—Å—Ç–æ—á–Ω–∏–∫: https://t.me/binance_announcements/{message_id}"
    main_body = f"{base_text}\n\n{source_link}".strip()

    tweets = _chunk_text(main_body)
    if not tweets and main_body:
        tweets = [main_body]

    hashtags_line = " ".join(hashtags).strip()
    if hashtags_line and tweets:
        if len(tweets[-1]) + 2 + len(hashtags_line) <= MAX_TWEET_LENGTH:
            tweets[-1] = f"{tweets[-1]}\n\n{hashtags_line}"
        else:
            tweets.append(hashtags_line)

    for tail in _chunk_text(BINANCE_LINKS_BLOCK):
        tweets.append(tail)

    return tweets


def _chunk_text(text: str) -> list[str]:
    """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏, –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–ª—è Twitter."""

    normalized = text.replace("\r\n", "\n").strip()
    if not normalized:
        return []

    chunks: list[str] = []
    paragraphs = normalized.split("\n\n")
    for paragraph in paragraphs:
        lines = textwrap.wrap(
            paragraph,
            width=MAX_TWEET_LENGTH,
            break_long_words=False,
            break_on_hyphens=False,
        )
        if not lines:
            continue
        for line in lines:
            if not chunks:
                chunks.append(line)
                continue
            candidate = f"{chunks[-1]}\n\n{line}"
            if len(candidate) <= MAX_TWEET_LENGTH:
                chunks[-1] = candidate
            else:
                chunks.append(line)
    return chunks
