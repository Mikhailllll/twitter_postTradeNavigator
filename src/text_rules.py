"""–ü—Ä–∞–≤–∏–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Ç–≤–∏—Ç–æ–≤."""

from __future__ import annotations

import re
import textwrap
from collections.abc import Iterable

MAX_TWEET_LENGTH = 270
BINANCE_LINKS_BLOCK = (
    "–ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏ Binance:\n"
    "‚Ä¢ –ë–∏—Ä–∂–∞: https://www.binance.com\n"
    "‚Ä¢ –ü–æ–¥–¥–µ—Ä–∂–∫–∞: https://www.binance.com/support\n"
    "‚Ä¢ –ê–∫–∞–¥–µ–º–∏—è: https://academy.binance.com"
)

EMOJI_KEYWORDS = {
    "–ª–∏—Å—Ç–∏–Ω–≥": "üÜï",
    "listing": "üÜï",
    "launchpool": "üöÄ",
    "maintenance": "üõ†Ô∏è",
    "upgrade": "üîß",
    "update": "üîÑ",
    "airdrop": "üéÅ",
    "bonus": "üí∞",
    "binance": "üü°",
}

CYRILLIC_PATTERN = re.compile("[–ê-–Ø–∞-—è–Å—ë]")
HASHTAG_WORD_PATTERN = re.compile(r"[A-Za-z0-9]{3,}")


def contains_cyrillic(text: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤."""

    return bool(CYRILLIC_PATTERN.search(text))


def insert_emojis(text: str) -> str:
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —ç–º–æ–¥–∑–∏ –≤ –Ω–∞—á–∞–ª–æ —Ç–µ–∫—Å—Ç–∞."""

    lowered = text.lower()
    emojis: list[str] = []
    for keyword, emoji in EMOJI_KEYWORDS.items():
        if keyword in lowered:
            emojis.append(emoji)
    if not emojis:
        emojis.append("üì¢")
    emojis_str = " ".join(dict.fromkeys(emojis))
    return f"{emojis_str} {text}".strip()


def generate_hashtags(text: str, *, limit: int = 2) -> list[str]:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–æ –¥–≤—É—Ö —Ö—ç—à—Ç–µ–≥–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞."""

    candidates = []
    for match in HASHTAG_WORD_PATTERN.finditer(text):
        word = match.group(0)
        if word.isdigit():
            continue
        candidates.append(word.lower())
    unique: list[str] = []
    for candidate in candidates:
        if candidate not in unique:
            unique.append(candidate)
    hashtags = [
        candidate.replace("/", "").replace("-", "") for candidate in unique[:limit]
    ]
    return [f"#{tag}" for tag in hashtags]


def build_thread(*, message_id: int, text: str, hashtags: Iterable[str]) -> list[str]:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç —Ç–≤–∏—Ç-–Ω–∏—Ç–∫—É —Å —Å—Å—ã–ª–∫–æ–π –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª –∏ –±–ª–æ–∫–æ–º —Å—Å—ã–ª–æ–∫ Binance."""

    base_text = insert_emojis(text)
    source_link = f"–ò—Å—Ç–æ—á–Ω–∏–∫: https://t.me/binance_announcements/{message_id}"
    main_body = f"{base_text}\n\n{source_link}".strip()

    tweets = _chunk_text(main_body)
    if not tweets and main_body:
        tweets = [main_body]

    safe_hashtags = _fit_hashtags(hashtags)
    hashtags_line = " ".join(safe_hashtags).strip()
    if hashtags_line and tweets:
        if len(tweets[-1]) + 2 + len(hashtags_line) <= MAX_TWEET_LENGTH:
            tweets[-1] = f"{tweets[-1]}\n\n{hashtags_line}"
        else:
            tweets.extend(
                _chunk_text(hashtags_line) or [hashtags_line[:MAX_TWEET_LENGTH]]
            )

    for tail in _chunk_text(BINANCE_LINKS_BLOCK):
        tweets.append(tail)

    return tweets


def _chunk_text(text: str) -> list[str]:
    """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏, –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–ª—è Twitter."""

    normalized = text.replace("\r\n", "\n").strip()
    if not normalized:
        return []

    chunks: list[str] = []
    paragraphs = normalized.split("\n\n")
    for paragraph in paragraphs:
        lines = textwrap.wrap(
            paragraph,
            width=MAX_TWEET_LENGTH,
            break_long_words=False,
            break_on_hyphens=False,
        )
        if not lines:
            continue
        for line in lines:
            for piece in _split_overflow(line):
                if not chunks:
                    chunks.append(piece)
                    continue
                candidate = f"{chunks[-1]}\n\n{piece}"
                if len(candidate) <= MAX_TWEET_LENGTH:
                    chunks[-1] = candidate
                else:
                    chunks.append(piece)
    return [chunk[:MAX_TWEET_LENGTH] for chunk in chunks]


def _fit_hashtags(hashtags: Iterable[str]) -> list[str]:
    """–û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ö—ç—à—Ç–µ–≥–æ–≤ —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω–∏ –ø–æ–º–µ—â–∞–ª–∏—Å—å –≤ —Ç–≤–∏—Ç."""

    result: list[str] = []
    current_length = 0
    for tag in hashtags:
        tag = tag.strip()
        if not tag:
            continue
        proposed_length = len(tag) if not result else current_length + 1 + len(tag)
        if proposed_length > MAX_TWEET_LENGTH:
            break
        result.append(tag)
        current_length = len(" ".join(result))
    return result


def _split_overflow(line: str) -> list[str]:
    """–î–µ–ª–∏—Ç —Å—Ç—Ä–æ–∫—É, –µ—Å–ª–∏ –æ–Ω–∞ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç Twitter."""

    if len(line) <= MAX_TWEET_LENGTH:
        return [line]

    pieces: list[str] = []
    start = 0
    while start < len(line):
        end = min(start + MAX_TWEET_LENGTH, len(line))
        pieces.append(line[start:end])
        start = end
    return pieces
